---
permalink: /
title: "Pengchao Feng - Homepage"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<span id="about-me"></span>

**Welcome to my homepage!** I am an undergraduate student at [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/), starting from September 2022, majoring in Artificial Intelligence. Now, I'm a member of the SJTU Cross Media Language Intelligence Lab ([X-LANCE](https://x-lance.github.io/)). 

My research interests focus on **Spoken Dialogue Systems**, **Text-to-Speech**, and **AI for Science**.

## Education <span id="-education"></span>

- *2022.09 – Present*: Shanghai Jiao Tong University (SJTU), College of Electronic Information and Electrical Engineering, Major in Artificial Intelligence.

## Publications <span id="-publications"></span>


<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge"></div>
      <a href="{{ '/images/pubs/hevector.png' | relative_url }}" class="image-popup">
        <img src="{{ '/images/pubs/hevector.png' | relative_url }}" alt="Task Vector in TTS" width="100%">
      </a>
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <strong>Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis</strong><br>
      <span style="color:#a05a20">Pengchao Feng</span>, Yao Xiao, Ziyang Ma, Zhikang Niu, Shuai Fan, Yao Li, Sheng Wang, and Xie Chen*.<br>
      preprint<br>
      <a href="https://arxiv.org/abs/2512.18699">arXiv</a> &nbsp;|&nbsp;
      <a href="https://github.com/the-bird-F/Expressive-Vectors">Code</a>
    </p>
  </div>
</div>

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge"></div>
      <a href="{{ '/images/pubs/e2erag.png' | relative_url }}" class="image-popup">
        <img src="{{ '/images/pubs/e2erag.png' | relative_url }}" alt="E2E-Retrieval" width="100%">
      </a>
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <strong>Enhance Speech-to-Speech Dialogue Modeling with End-to-End Retrieval Augmented Generation</strong><br>
      <span style="color:#a05a20">Pengchao Feng</span>, Ziyang Ma, Wenxi Chen, Yao Li, Sheng Wang, Kai Yu, and Xie Chen*.<br>
      EMNLP 2025 Findings<br>
      <a href="http://arxiv.org/abs/2505.00028">arXiv</a> &nbsp;|&nbsp;
      <a href="https://github.com/the-bird-F/GLM-Voice-RAG">Code</a>
    </p>
  </div>
</div>

---

<div class="paper-box">
  <div class="paper-box-image">
    <div>
      <div class="badge"></div>
      <a href="{{ '/images/pubs/xtalk.png' | relative_url }}" class="image-popup">
        <img src="{{ '/images/pubs/xtalk.png' | relative_url }}" alt="X-Talk" width="100%">
      </a>
    </div>
  </div>
  <div class="paper-box-text">
    <p>
      <strong>X-Talk: On the Underestimated Potential of Modular Speech-to-Speech Dialogue System</strong><br>
      Zhanxun Liu, Yifan Duan, Mengmeng Wang, <span style="color:#a05a20">Pengchao Feng</span>, Haotian Zhang, Xiaoyu Xing, Yijia Shan, Haina Zhu, Yuhang Dai, Chaochao Lu, Xipeng Qiu, Lei Xie, Lan Wang, Nan Yan, Zilong Zheng, Ziyang Ma, Kai Yu, and Xie Chen*.<br>
      preprint<br>
      <a href="https://arxiv.org/abs/2512.18706">arXiv</a> &nbsp;|&nbsp;
      <a href="https://github.com/xcc-zach/xtalk">Code</a>
    </p>
  </div>
</div>


## Internships <span id="-internships"></span>

- *2025.06 – 2025.10*: **Shanghai Innovation Institute**, Research Intern  
  - Working on speech synthesis system for Chinese dialects

- *2025.11 – Present*: **Tongyi Speech Lab**, Research Intern  
  - Working on End-to-End Speech Language Model


## Honors and Awards <span id="-honors-and-awards"></span>

- *2025.10*: National College Student Scholarship  
- *2024.12*: National College Student Mathematical Modeling Competition, Shanghai Region Third Prize  
- *2024.10*: Bosch China Long-term Development Scholarship  
- *2024.10*: SJTU Second Prize Scholarship  
- *2023.10*: SJTU Third Prize Scholarship

